# crawler
Repository for the web crawler project in Python

I. Pré-requisitos e links para instalação: 
------------

- Python versões 2.7, 3.5 e acima (https://www.python.org/downloads/)
- Beautiful Soup 4 (http://beautiful-soup-4.readthedocs.io/en/latest/#installing-beautiful-soup)
- Google Chrome browser versão 66-68 (https://www.google.com/chrome/?brand=CHBD&gclid=CjwKCAjwo87YBRBgEiwAI1Lkqc93bonUzTAvmYjtFNDBTVuCRW-doMvMKebPe1ZE7fUOCKY5POMCARoCwdwQAvD_BwE)
- Selenium 2 WebDriver API (http://selenium-python.readthedocs.io/installation.html)
- ChromeDriver 2.39 (https://sites.google.com/a/chromium.org/chromedriver/downloads)

Cheque se o ChromeDriver está no seu PATH: coloque-o em /usr/bin em /usr/local/bin.



II. Instalação e Execução
----------

1. Faça o download do arquivo crawler.py

2. Rode crawler.py
No terminal do Ubuntu, rode o comando "python crawler.py" no diretório em que o arquivo craler.py se encontra. 

3. Tempo de Execução
O chrome será aberto e fechado diversas vezes enquanto o programa estiver rodando. Espere o programa parar de rodar para ver o resultado.

4. Arquivo de Saída
Quando o programa finalizar sua execução, terá sido gerado um arquivo csv com os resultados. O arquivo de saída se chamará URLs.csv e estará no mesmo diretório que o arquivo crawler.py.



III. Resultados
----------

Os resultados aparecem na forma de um arquivo csv de saída. Ele é composto por três colunas (URLs, Nomes dos produtos e títulos dos produtos).
